
# 01. 데이터 전환

* 데이터 전환
- 운영 중인 기본 정보 시스템에 축적되어있는 데이터를 '추출(Extractioin)' 하여 새로 개발할 정보 시스템에 운영할 수 있도록 '변환(Transformation)' 한 후, '적재(Loading)' 하는 일련의 과정
- ETL(Extraction, Transformation, Load), 추출, 변환, 적재 과정이라고 함
- '데이터 이행(Data Migration)' 또는 '데이터 이관' 이라고 함

* 데이터 전환 계획서
- 데이터 전환이 필요한 대상을 분석하여 '데이터 전환 작업에 필요한 모든 계획을 기록하는 문서'

** 주요 항목
- 데이터 전환 개요
- 데이터 전환 대상 및 범위
- 데이터 전환 환경 구성
- 데이터 전환 조직 및 역할
- 데이터 전환 일정
- 데이터 전환 방안
- 데이터 정비 방안
- 비상 계획
- 데이터 복구 대책


# 02. 데이터 검증

* 데이터 검증
- 원천 시스템의 데이터를 목적 시스템의 데이터로 전환하는 과정이 정상적으로 수행되었는지 여부를 확인하는 과정
- 데이터 전환 검증은 '검증 방법' 과 '검증 단계' 에 따라 분류할 수 있음

** '검증 방법'에 따른 분류
1) 로그 검증 : 데이터 전환 과정에서 작성하는 추출, 전환, 적재 로그를 검증
2) 기본 항목 검증 : 로그 검증 외에 별도로 요청된 검증 항목에 대해 검증
3) 응용 프로그램 검증 : 응용 프로그램을 통한 데이터 전환의 정합성을 검증
4) 응용 데이터 검증 : 사전에 정의된 업무 규칙을 기준으로 데이터 전환의 정합성을 검증
5) 값 검증 : 숫자 항목의 합계 검증, 코드 데이터의 범위 검증, 속성 변경에 따른 값 검증을 수행

*** '검증 단계'에 따른 분류
1) 추출 : 원천 시스템 데이터에 대한 정합성 확인 => 로그 검증
2) 전환 : 매핑 정의서에 정의된 내용이 정확히 반영되었는지 확인, 매핑 정의서 오류 여부 확인 => 로그 검증
3) DB 적재 : SAM 파일을 적재하는 과정에서 발생할 수 있는 오류나 데이터 누락 여부 등 확인 => 로그 검증
4) DB 적재 후 : 적재 완료 후 정합성 확인 => 기본 항목 검증
5) 전환 완료 후 : 데이터 전환 완료 후 추가 검증 과정을 통해 데이터 전환의 정합성 검증 => 응용 프로그램, 응용 데이터 검증


# 03. 오류 데이터 측정 및 정제

* 오류 데이터 측정 및 정제
- 고품질의 데이터를 운영 및 관리하기 위해 수행

** 진행 과정
1) 데이터 품질 분석 : 오류 데이터를 찾기 위해 원천 및 목적 시스템 데이터의 정합성 여부를 확인하는 작업
2) 오류 데이터 측정 : 데이터 품질 분석을 기반으로 정상 데이터와 오류 데이터의 수를 측정하여 오류 관리 목록을 작성
3) 오류 데이터 정제 : 오류 관리 목록의 각 항목을 분석하여 원천 데이터를 정의하거나 전환 프로그램을 수정

*** 오류 상태
1) Open : 오류가 보고만 되고 분석되지 않은 상태
2) Assigned : 오류의 영향 분석 및 수정을 위해 개발자에게 오류를 전달한 상태
3) Fixed : 개발자가 오류를 수정한 상태
4) Closed : 수정된 오류에 대해 테스트를 다시 했을 때 오류가 발견되지 않은 상태
5) Deferred : 오류 수정을 연기한 상태
6) Classified : 보고된 오류를 관련자들이 확인했을 때 오류가 아니라고 확인된 상태

* 데이터 정제요청서
- 원천 데이터의 정제와 전환 프로그램의 수정을 위해 요청사항 및 조치사항 등 '데이터 정제와 관련된 전반적인 내용을 문서로 작성한 것'
- 오류 관리 목록을 기반으로 '데이터 정제 요건 목록' 을 작성하고, 이 목록의 항목별로 '데이터 정제요청서' 를 작성

* 데이터 정제 보고서
- 데이터 정제요청서를 통해 '정체된 원천 데이터가 정상적으로 정제되었는지 확인한 결과를 문서로 작성한 것'
- 정제 요청 데이터와 정제된 데이터 항목을 눈으로 직접 비교하여 확인


# 04. 데이터베이스 개요

* 데이터저장소
- 데이터들을 논리적인 구조로 조직화하거나, 물리적인 공간에 구축한 것

-- 논리 데이터저장소 : 데이터 및 데이터 간의 연관성, 제약 조건을 식별하여 논리적인 구조로 조직화한 것
-- 물리 데이터저장소 : 논리 데이터저장소를 소프트웨어가 운용될 환경의 물리적 특성을 고려하여 실제 저장장치에 저장한 것

* 데이터베이스 (Database)
- 여러 사람에 의해 '공동' 으로 사용될 데이터를 중복을 배제하여 '통합' 하고, 쉽게 접근하여 처리할 수 있도록 저장장치에 '저장' 하여 항상 사용할 수 있도록 운영하는 '운영' 데이터

** 데이터베이스 4가지 정의
1) 통합된 데이터 (Integrated Data) : 자료의 중복을 배제한 데이터의 모임
2) 저장된 데이터 (Stored Data) : 컴퓨터가 접근할 수 있는 저장 매체에 저장된 자료
3) 운영 데이터 (Operational Data) : 조직의 고유한 업무를 수행하는 데 반드시 필요한 자료
4) 공용 데이터 (Shared Data) : 여러 응용 시스템들이 공동으로 소유하고 유지하는 자료

* DBMS (DataBase Management System, 데이터베이스 관리 시스템)
- '사용자의 요구에 따라 정보를 생성해주고, 데이터베이스를 관리해주는 소프트웨어'
- 기존의 파일 시스템이 갖는 데이터의 '종속성' 과 '중복성' 문제를 해결하기 위해 제안된 시스템

** 필수 기능 3가지
1) 정의 (Definition) 기능 : 데이터의 형(Type) 과 구조에 대한 정의, 이용 방식,제약 조건 등을 명시하는 기능
2) 조작 (Manipulation) 기능 : 데이터 검색, 갱신, 삽입, 삭제 등을 위해 인터페이스 수단을 제공하는 기능
3) 제어 (Control) 기능 : 데이터의 무결성, 보안, 권한 검사, 병행 제어를 제공하는 기능

* 데이터의 독립성
- 데이터의 종속성에 대비되는 말로, '논리적 독립성' 과 '물리적 독립성' 이 있음

-- 논리적 독립성 : '응용 프로그램' 과 '데이터베이스' 를 독립시킴으로써, 데이터의 논리적 구조를 변경시키더라도 응용 프로그램은 영향을 받지 않음
-- 물리적 독립성 : '응용 프로그램' 과 보조기억장치 같은 '물리적 장치' 를 독립시킴으로써, 디스크를 추가/변경 하더라도 응용 프로그램은 영향을 받지 않음

* 스키마 (Schema)
- '데이터베이스의 구조와 제약 조건에 관한 전반적인 명세를 기술한 것'

** 종류
1) 외부 스키마 : 사용자나 응용 프로그래머가 각 개인의 입장에서 필요로 하는 데이터베이스의 논리적 구조를 정의한 것
2) 개념 스키마 : 데이터베이스의 전체적인 논리적 구조 / 모든 응용 프로그램이나 사용자들이 필요로 하는 데이터를 종합한 조직 전체의 데이터베이스로, 하나만 존재함
3) 내부 스키마 : 물리적 저장장치의 입장에서 본 데이터베이스 구조 / 실제로 저장될 레코드의 형식, 저장 데이터 항목의 표현 방법, 내부 레코드의 물리적 순서 등을 나타냄


# 05. 데이터베이스 설계

* 데이터베이스 설계
- 사용자의 요구를 분석하여 그것들을 컴퓨터에 저장할 수 있는 데이터베이스의 구조에 맞게 변형한 후, DBMS로 데이터베이스를 구현하여 일반 사용자들이 사용하게 하는 것

* 데이터베이스 설계 시 고려사항
1) 무결성 : 삽입, 삭제, 갱신 등의 연산 후에도 데이터베이스에 저장된 데이터가 정해진 제약 조건을 항상 만족해야 함
2) 일관성 : 데이터베이스에 저장된 데이터들 사이나, 특정 질의에 대한 응답이 처음부터 끝까지 변함없이 일정해야 함
3) 회복 : 시스템에 장애가 발생했을 때 장애 발생 직전의 상태로 복구할 수 있어야 함
4) 보안 : 불법적인 데이터의 노출 또는 변경이나 손실로부터 보호할 수 있어야 함
5) 효율성 : 응답시간의 단축, 시스템의 생산성, 저장 공간의 최적화 등이 가능해야 함
6) 데이터베이스 확장 : 데이터베이스 운영에 영향을 주지 않으면서 지속적으로 데이터를 추가할 수 있어야 함

* 데이터베이스 설계 순서
1) 요구 조건 분석 : 요구 조건 명세서 작성
- '데이터베이스'를 사용할 사람들로부터 '필요한 용도를 파악하는 것'
- 데이터베이스 사용자에 따른 수행 업무와 필요한 데이터의 종류, 용도, 처리 형태, 흐름, 제약 조건 등을 수집
- 수집된 정보를 바탕으로 '요구 조건 명세'를 작성

2) 개념적 설계 (정보 모델링, 개념화) : 개념 스키마, 트랜잭션 모델링, E-R 모델
- 정보의 구조를 얻기 위하여 현실 세계의 무한성과 계속성을 이해하고, 다른 사람과 통신하기 위하여 '현실 세계에 대한 인식을 추상적 개념으로 표현하는 과정'
- 개념적 설계에는 '개념 스키마 모델링' 과 '트랜잭션 모델링' 을 '병행 수행' 함
- 개념적 설계에서는 요구 분석에서 나온 결과인 요구 조건 명세를 DBMS에 독립적인 'E-R 다이어그램' 으로 작성
- DBMS에 독립적인 '개념 스키마' 를 설계

3) 논리적 설계 (데이터 모델링) : 목표 DBMS에 맞는 논리 스키마 설계, 트랜잭션 인터페이스 설계
- 현실 세계에서 발생하는 자료를 컴퓨터가 이해하고 처리할 수 있는 물리적 저장장치에 저장할 수 있도록 변환하기 위해 '특정 DBMS가 지원하는 논리적 자료 구조로 변환(Mapping) 시키는 과정'
- 개념 세계의 데이터를 필드로 기술된 데이터 타입과 이 데이터 타입들 간의 관계로 표현되는 논리적 구조의 데이터로 모델화 함
- 개념적 설계가 '개념 스키마'를 설계하는 단계라면, 논리적 설계에서는 개념 스키마를 평가 및 정제하고, DBMS에 따라 서로다른 '논리적 스키마'를 설계하는 단계
- 트랜잭션의 인터페이스를 설계

4) 물리적 설계 (데이터 구조화) : 목표 DBMS에 맞는 물리적 구조의 데이터로 변환
- 논리적 설계에서 '논리적 구조로 표현된 데이터'를 디스크 등의 물리적 저장장치에 저장할 수 있는 '물리적 구조의 데이터로 변환하는 과정'
- 물리적 설계에서는 다양한 데이터베이스 응용에 대해 처리 성능을 얻기 위해 '데이터베이스 파일의 저장 구조 및 엑세스 경로' 를 결정
- 저장 레코드의 형식, 순서, 접근 경로, 조회 집중 레코드 등 정보를 사용하여 데이터가 컴퓨터에 저장되는 방법을 묘사

5) 데이터베이스 구현 : 목표 DBMS의 DDL(데이터 정의어)로 데이터베이스 생성, 트랜잭션 작성
- '논리적 설계와 물리적 설계에서 도출된 데이터베이스 스키마를 '파일'로 생성하는 과정'
- 사용하려는 특정 DBMS의 'DDL(데이터 정의어)' 을 이용하여 데이터베이스 스키마를 기술한 후, 컴파일하여 빈 데이터베이스 파일을 생성
- 응용 프로그램을 위한 '트랜잭션'을 작성
- 데이터베이스 접근을 위한 '응용 프로그램'을 작성


# 06. 데이터 모델의 개념

* 데이터 모델
- '현실 세계의 정보들을' 컴퓨터에 표현하기 위해서 단순화, 추상화하여 '체계적으로 표현한 개념적 모형'
- 데이터, 데이터의 관계, 데이터의 의미 및 일관성, 제약 조건 등을 기술하기 위한 개념적 도구들로 구성되어 있음
- 데이터베이스 설계 과정에서 데이터의 구조(Schema) 를 논리적으로 표현하기위해 지능적 도구로 사용됨

** 구성 요소
- 개체, 속성, 관계

** 종류
- 개념적 데이터 모델, 논리적 데이터 모델, 물리적 데이터 모델

** 표시할 요소
- 구조, 연산, 제약 조건

* 개념적 데이터 모델
- '현실 세계에 대한 인간의 이해를 돕기 위해 현실 세계에 대한 인식을 추상적 개념으로 표현하는 과정'
- 속성들로 기술된 개체 타입과 이 개체 타입 간의 관계를 이용하여 현실 세계를 표현함
- 현실 세계에 존재하는 개체를 인간이 이해할 수 있는 정보 구조로 표현하기 때문에 '정보 모델' 이라고도 함
- 대표적인 모델로 'E-R 모델' 이 있음

* 논리적 데이터 모델
- 개념적 모델링 과정에서 얻은 '개념적 구조'를 컴퓨터가 이해하고 처리할 수 있는 '컴퓨터 세계의 한경에 맞도록 변환하는 과정'
- 필드로 기술된 데이터 타입과 이 데이터 타입들 간의 관계를 이용하여 현실 세계를 표현
- 단순히 '데이터 모델' 이라고 하면 논리적 데이터 모델을 의미
- 특정 DBMS는 특정 논리적 데이터 모델 하나만 선정하여 사용
- 데이터 간의 관계를 어떻게 표현하느냐에 따라 '관계 모델', '계층 모델', '네트워크 모델' 로 구분함

* 데이터 모델에 표시할 요소
1) 구조 (Structure) : 논리적으로 표현된 개체 타입들 간의 관계로서 데이터 구조 및 정적 성질 표현
2) 연산 (Operation) : 데이터베이스에 저장된 실제 데이터를 처리하는 작업에 대한 명세로서 데이터베이스를 조작하는 기본 도구
3) 제약 조건 (Constraint) : 데이터베이스에 저장될 수 있는 실제 데이터의 논리적인 제약 조건


# 07. 데이터 모델의 구성 요소

* 개체 (Entity)
- '데이터베이스에 표현하려는 것' 으로, 사람이 생각하는 '개념이나 정보 단위 같은 현실 세계의 대상체'
- 실세계에 독립적으로 존재하는 '유형', '무형' 의 정보로서 서로 연관된 몇 개의 '속성'으로 구성됨
- 독립적으로 존재하나 그 자체로서도 구별이 가능하며, '유일한 식별자(Unique Identifier)' 에 의해 식별됨
- 다른 개체와 하나 이상의 '관계(Relationship)' 가 있음

* 속성 (Attribute)
- '데이터베이스를 구성하는 가장 작은 논리적 단위'
- 파일 구조상의 '데이터 항목' 또는 '데이터 필드' 에 해당
- 개체를 구성하는 항목으로 개체의 특성을 기술
- 속성의 수를 '디그리(Degree)' 또는 '차수' 라고 함
- 속성은 속성의 '특성'과 '개체 구성 방식'에 따라 분류

** 속성의 '특성'에 따른 분류
1) 기본 속성 (Basic Attiribute) : 
- 업무 분석을 통해 정의한 속성 / 속성 중 가장 많고 일반적임
- 업무로부터 분석한 속성이라도 업무상 코드로 정의한 속성은 기본 속성에서 제외

=> ex) 자동차명, 제조일, 연비

2) 설계 속성 (Designed Attribute)
- 원래 업무상 존재하지 않고, 설계 과정에서 도출해내는 속성
- 업무에 필요한 데이터 외에 데이터 모델링을 위해 업무를 규칙화하려고 속성을 새로 만들거나 변형하여 정의하는 속성

=> ex) 자동차코드

3) 파생 속성 (Derived Attribute)
- 다른 속성으로부터 계산이나 변형 등의 영향을 받아 발생하는 속성
- 되도록 적은 수를 정의하는 것이 좋음 => 다른 속성의 영향을 받는 만큼, 프로세스 설계 시 정합성 유지를 위해 유의해야 할 점이 많으므로

=> ex) 총판매수량, 총판매금액

** 속성의 '개체 구성 방식'에 따른 분류
1) 기본키 속성 (Primary Key Attribute) : 개체를 유일하게 식별할 수 있는 속성
2) 외래키 속성 (Foreign Key Attribute) : 다른 개체와의 관계에서 포함된 속성
3) 일반 속성 : 개체에 포함되어 있고 기본키, 외래키에 포함되지 않은 속성

* 관계 (Relationship)
- '개체와 개체 사이의 논리적인 연결'
- '개체 간의 관계' 와 '속성 간의 관계' 가 있음

* 관계의 형태
1) 일 대 일 (1 : 1) - 개체 집합 A의 각 원소가 개체 집합 B의 원소 '한 개' 와 대응하는 관계
2) 일 대 다 (1 : N) - 개체 집합 A의 각 원소는 개체 집합 B의 원소 '여러 개' 와 대응하고 있지만, 개체 집합 B의 각 원소는 개체 집합 A의 원소 '한 개' 와 대응하는 관계
3) 다 대 다 (N : M) - 개체 집합 A의 각 원소는 개체 집합 B의 원소 '여러 개' 와 대응하고, 개체 집합 B의 각 원소도 개체 집합 A의 원소 '여러 개' 와 대응하는 관계

* 관계의 종류
1) 종속 관계 (Dependent Relationship) : 두 개체 사이의 '주종 관계' 를 표현한 것 / '식별 관계', '비식별 관계' 가 있음
2) 중복 관계 (Redunant Relationship) : 두 개체 사이의 '2번 이상' 의 '종속 관계' 가 발생하는 관계
3) 재귀 관계 (Recursive Relationship) : 개체가 자기 자신과 관계를 갖는 것으로, '순환 관계(Recursive Relationship)' 라고도 함
4) 배타 관계 (Exclusive Relationship) : 개체의 '속성' 이나 '구분자' 를 기준으로 개체의 특성을 분할하는 관계 / '배타 AND 관계' 와 '배타 OR 관계' 로 구분함












































